Epoch 1, Batch 100/1853, Train Loss: 9.56553230935242e-06, Val Loss: 2.5058834444155835e-10, Val R^2: -0.007102961355053857
Best model saved to ../model_0327_Mixer/model_best_0_r2_-0.007102961355053857.pth with Val Loss: 2.5058834444155835e-10, Val R^2: -0.007102961355053857
Epoch 1, Batch 200/1853, Train Loss: 9.876802323560696e-06, Val Loss: 2.499435556784708e-10, Val R^2: -0.003489402509144639
Best model saved to ../model_0327_Mixer/model_best_0_r2_-0.003489402509144639.pth with Val Loss: 2.499435556784708e-10, Val R^2: -0.003489402509144639
Epoch 1, Batch 300/1853, Train Loss: 9.44673411140684e-06, Val Loss: 2.502724075664502e-10, Val R^2: -0.005283822241449121
Epoch 1, Batch 400/1853, Train Loss: 9.392732863489073e-06, Val Loss: 2.5010605321975546e-10, Val R^2: -0.004415192602687397
Epoch 1, Batch 500/1853, Train Loss: 1.0233998182229698e-05, Val Loss: 2.50644889620501e-10, Val R^2: -0.00741709309194705
Epoch 1, Batch 600/1853, Train Loss: 9.34064792090794e-06, Val Loss: 2.5019366875374493e-10, Val R^2: -0.004917416846138602
Epoch 1, Batch 700/1853, Train Loss: 9.84722555585904e-06, Val Loss: 2.5011332428523753e-10, Val R^2: -0.004489618897020537
Epoch 1, Batch 800/1853, Train Loss: 9.944105840986595e-06, Val Loss: 2.4967945953782305e-10, Val R^2: -0.002229863400435241
Best model saved to ../model_0327_Mixer/model_best_0_r2_-0.002229863400435241.pth with Val Loss: 2.4967945953782305e-10, Val R^2: -0.002229863400435241
Epoch 1, Batch 900/1853, Train Loss: 9.662922821007669e-06, Val Loss: 2.501330270044099e-10, Val R^2: -0.004590775475495803
Epoch 1, Batch 1000/1853, Train Loss: 9.476088962401263e-06, Val Loss: 2.503629960106362e-10, Val R^2: -0.005877433168261967
Epoch 1, Batch 1100/1853, Train Loss: 9.409524864167906e-06, Val Loss: 2.5000524097332346e-10, Val R^2: -0.003834437446382115
Epoch 1, Batch 1200/1853, Train Loss: 9.398787369718775e-06, Val Loss: 2.5072779355591126e-10, Val R^2: -0.007847066491238956
Epoch 1, Batch 1300/1853, Train Loss: 9.814091754378751e-06, Val Loss: 2.5137114279515e-10, Val R^2: -0.011533855268427947
Epoch 1, Batch 1400/1853, Train Loss: 9.46264208323555e-06, Val Loss: 2.507996502394434e-10, Val R^2: -0.008260864145267669
Epoch 1, Batch 1500/1853, Train Loss: 9.292502909374889e-06, Val Loss: 2.5149320579151986e-10, Val R^2: -0.012206879042711978
Epoch 1, Batch 1600/1853, Train Loss: 1.003482611849904e-05, Val Loss: 2.5044021804271744e-10, Val R^2: -0.006298775174760957
Epoch 1, Batch 1700/1853, Train Loss: 9.679702088760678e-06, Val Loss: 2.498793912742218e-10, Val R^2: -0.0031768331476868484
Epoch 1, Batch 1800/1853, Train Loss: 9.17277156986529e-06, Val Loss: 2.50285329135687e-10, Val R^2: -0.005409312614134997
/usr/local/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([26960])) that is different to the input size (torch.Size([26960, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Epoch 2, Batch 100/1853, Train Loss: 9.848056834016461e-06, Val Loss: 2.50709711192996e-10, Val R^2: -0.007774500187650649
Epoch 2, Batch 200/1853, Train Loss: 9.47656462813029e-06, Val Loss: 2.5000626815594577e-10, Val R^2: -0.0038089682842112164
Epoch 2, Batch 300/1853, Train Loss: 9.335839422419667e-06, Val Loss: 2.556779137988244e-10, Val R^2: -0.036290346605586755
Epoch 2, Batch 400/1853, Train Loss: 1.0800685231515672e-05, Val Loss: 2.781516703361957e-10, Val R^2: -0.16695554146674568
Epoch 2, Batch 500/1853, Train Loss: 9.847098226600792e-06, Val Loss: 2.5195243485724934e-10, Val R^2: -0.016239196668806112
Epoch 2, Batch 600/1853, Train Loss: 9.394456355948932e-06, Val Loss: 2.505716913663428e-10, Val R^2: -0.006945097612414969
Epoch 2, Batch 700/1853, Train Loss: 9.563855201122351e-06, Val Loss: 2.5047848794095606e-10, Val R^2: -0.006437029341932197
Epoch 2, Batch 800/1853, Train Loss: 9.802274689718615e-06, Val Loss: 2.5334260227379933e-10, Val R^2: -0.02276388925474874
Epoch 2, Batch 900/1853, Train Loss: 9.21811442822218e-06, Val Loss: 2.5076379866879585e-10, Val R^2: -0.008063745486925523
Epoch 2, Batch 1000/1853, Train Loss: 9.156117812381126e-06, Val Loss: 2.5095486444307445e-10, Val R^2: -0.010184697324615239
Epoch 2, Batch 1100/1853, Train Loss: 9.564808351569809e-06, Val Loss: 2.5028965854111397e-10, Val R^2: -0.005316952822590822
Epoch 2, Batch 1200/1853, Train Loss: 9.742961992742494e-06, Val Loss: 2.497467738554606e-10, Val R^2: -0.0026072887911377904
Epoch 2, Batch 1300/1853, Train Loss: 9.774357749847695e-06, Val Loss: 2.559406307491301e-10, Val R^2: -0.03773753053902419
Epoch 2, Batch 1400/1853, Train Loss: 9.693134416011162e-06, Val Loss: 2.4979295013287533e-10, Val R^2: -0.002624254825813119
Epoch 2, Batch 1500/1853, Train Loss: 9.513906661595684e-06, Val Loss: 2.524129423582326e-10, Val R^2: -0.018975768487239086
Epoch 2, Batch 1600/1853, Train Loss: 9.875900104816537e-06, Val Loss: 2.549808462949607e-10, Val R^2: -0.03216445709846468
Epoch 2, Batch 1700/1853, Train Loss: 1.0386806025053374e-05, Val Loss: 2.5051382964677376e-10, Val R^2: -0.0065621653739474
Epoch 2, Batch 1800/1853, Train Loss: 9.775191756489221e-06, Val Loss: 2.5093190631093273e-10, Val R^2: -0.00893520898596669
Epoch 3, Batch 100/1853, Train Loss: 1.3611235772259533e-05, Val Loss: 3.447688438294746e-10, Val R^2: -0.4823214668069588
Epoch 3, Batch 200/1853, Train Loss: 9.606188541511074e-06, Val Loss: 2.5069292934403576e-10, Val R^2: -0.007574462872946371
Epoch 3, Batch 300/1853, Train Loss: 1.0072239092551172e-05, Val Loss: 2.509947653633388e-10, Val R^2: -0.009281512347824433
Epoch 3, Batch 400/1853, Train Loss: 9.931769454851747e-06, Val Loss: 2.580185541547498e-10, Val R^2: -0.0497100090227755
Epoch 3, Batch 500/1853, Train Loss: 9.303895240009297e-06, Val Loss: 2.518506831826269e-10, Val R^2: -0.015542861289532717
Epoch 3, Batch 600/1853, Train Loss: 9.621708159102127e-06, Val Loss: 2.506250146613083e-10, Val R^2: -0.0072087680780566245
Epoch 3, Batch 700/1853, Train Loss: 1.0796356036735233e-05, Val Loss: 2.63729073983569e-10, Val R^2: -0.08289120231231499
Epoch 3, Batch 800/1853, Train Loss: 9.313476766692474e-06, Val Loss: 2.5047294108755084e-10, Val R^2: -0.006346806214675256
Epoch 3, Batch 900/1853, Train Loss: 1.0081895197799895e-05, Val Loss: 2.497142145516551e-10, Val R^2: -0.0022516347399622536
Epoch 3, Batch 1000/1853, Train Loss: 9.489776857662946e-06, Val Loss: 2.5289147439162427e-10, Val R^2: -0.02012281870095991
Epoch 3, Batch 1100/1853, Train Loss: 9.983192285289988e-06, Val Loss: 2.528031369662925e-10, Val R^2: -0.019617325246659795
Epoch 3, Batch 1200/1853, Train Loss: 9.395434062753338e-06, Val Loss: 2.5125584316620843e-10, Val R^2: -0.01075588042512077
Epoch 3, Batch 1300/1853, Train Loss: 9.672602573118638e-06, Val Loss: 2.614961668371065e-10, Val R^2: -0.06990420173574088
Epoch 3, Batch 1400/1853, Train Loss: 1.0462740647199098e-05, Val Loss: 2.702449642010365e-10, Val R^2: -0.12486227637004282
Epoch 3, Batch 1500/1853, Train Loss: 9.502021384832915e-06, Val Loss: 2.49814471916616e-10, Val R^2: -0.002711537162721859
Epoch 3, Batch 1600/1853, Train Loss: 1.0114505130331963e-05, Val Loss: 2.548287964436657e-10, Val R^2: -0.03127847900346369
Epoch 3, Batch 1700/1853, Train Loss: 9.522011168883182e-06, Val Loss: 2.514036417654487e-10, Val R^2: -0.011618140651697766
Epoch 3, Batch 1800/1853, Train Loss: 9.594133189239074e-06, Val Loss: 2.502617842181641e-10, Val R^2: -0.0058801432843798886
Epoch 4, Batch 100/1853, Train Loss: 9.866977961792145e-06, Val Loss: 2.591048490439758e-10, Val R^2: -0.05600717800850323
Epoch 4, Batch 200/1853, Train Loss: 9.918811883835588e-06, Val Loss: 2.592944358254583e-10, Val R^2: -0.057122060768649466
Epoch 4, Batch 300/1853, Train Loss: 1.2085236448911019e-05, Val Loss: 2.868689480192259e-10, Val R^2: -0.217332730659998
Epoch 4, Batch 400/1853, Train Loss: 9.717646207718644e-06, Val Loss: 2.551262670255497e-10, Val R^2: -0.0352127534426656
Epoch 4, Batch 500/1853, Train Loss: 9.6680687420303e-06, Val Loss: 2.527827075365689e-10, Val R^2: -0.019497845421077437
Epoch 4, Batch 600/1853, Train Loss: 9.384630175190978e-06, Val Loss: 2.496788743588448e-10, Val R^2: -0.002123145623857088
Best model saved to ../model_0327_Mixer/model_best_3_r2_-0.002123145623857088.pth with Val Loss: 2.496788743588448e-10, Val R^2: -0.002123145623857088
Epoch 4, Batch 700/1853, Train Loss: 1.0538173228269443e-05, Val Loss: 2.579636720324966e-10, Val R^2: -0.052110333957805
Epoch 4, Batch 800/1853, Train Loss: 1.02133772088564e-05, Val Loss: 2.7369482216274796e-10, Val R^2: -0.14507786309291715
Epoch 4, Batch 900/1853, Train Loss: 1.0107835805683862e-05, Val Loss: 2.5380894406224414e-10, Val R^2: -0.027317957058207252
Epoch 4, Batch 1000/1853, Train Loss: 9.564287211105693e-06, Val Loss: 2.510375028923759e-10, Val R^2: -0.00953579365618087
Epoch 4, Batch 1100/1853, Train Loss: 1.1063057172577828e-05, Val Loss: 2.6402378448497035e-10, Val R^2: -0.08815309420827987
Epoch 4, Batch 1200/1853, Train Loss: 1.0348732757847756e-05, Val Loss: 2.613408940558045e-10, Val R^2: -0.0689742316858322
Epoch 4, Batch 1300/1853, Train Loss: 9.406321623828262e-06, Val Loss: 2.5023571076633494e-10, Val R^2: -0.005004166446409124
Epoch 4, Batch 1400/1853, Train Loss: 1.0806405953189824e-05, Val Loss: 2.7356513702713147e-10, Val R^2: -0.14010564012986026
Epoch 4, Batch 1500/1853, Train Loss: 1.2228708328620996e-05, Val Loss: 2.9232201020501365e-10, Val R^2: -0.24911505685713842
Epoch 4, Batch 1600/1853, Train Loss: 1.00508104878827e-05, Val Loss: 2.5457586855813353e-10, Val R^2: -0.029827275217515475
Epoch 4, Batch 1700/1853, Train Loss: 1.0232715794700198e-05, Val Loss: 2.5087923874592227e-10, Val R^2: -0.00861470775983909
Epoch 4, Batch 1800/1853, Train Loss: 1.0432408089400269e-05, Val Loss: 2.4982429157776224e-10, Val R^2: -0.0031277755606670065
Epoch 5, Batch 100/1853, Train Loss: 9.630831300455611e-06, Val Loss: 2.52344980006431e-10, Val R^2: -0.016986390205141172
Epoch 5, Batch 200/1853, Train Loss: 9.457858141104225e-06, Val Loss: 2.526533426915532e-10, Val R^2: -0.01875575179675829
Epoch 5, Batch 300/1853, Train Loss: 1.0373047189204954e-05, Val Loss: 2.545602550871446e-10, Val R^2: -0.029739526803877744
Epoch 5, Batch 400/1853, Train Loss: 9.703051546239294e-06, Val Loss: 2.5075515041163586e-10, Val R^2: -0.007925475164723353
Epoch 5, Batch 500/1853, Train Loss: 9.332379704574123e-06, Val Loss: 2.5094031173973733e-10, Val R^2: -0.010041096630756233
Epoch 5, Batch 600/1853, Train Loss: 1.0108555215992965e-05, Val Loss: 2.607876579522648e-10, Val R^2: -0.06892864117189566
Epoch 5, Batch 700/1853, Train Loss: 9.395376764587127e-06, Val Loss: 2.508922682056653e-10, Val R^2: -0.00974402146068361
Epoch 5, Batch 800/1853, Train Loss: 9.091769243241288e-06, Val Loss: 2.498303351272288e-10, Val R^2: -0.002792713414597419
Epoch 5, Batch 900/1853, Train Loss: 1.0432874660182279e-05, Val Loss: 2.625240088317928e-10, Val R^2: -0.07586621561650786
Epoch 5, Batch 1000/1853, Train Loss: 1.051536946761189e-05, Val Loss: 2.6498029609856613e-10, Val R^2: -0.09014101539473109
Epoch 5, Batch 1100/1853, Train Loss: 9.722454706206918e-06, Val Loss: 2.505660275257076e-10, Val R^2: -0.007758735398903375
Epoch 5, Batch 1200/1853, Train Loss: 1.0550686056376435e-05, Val Loss: 2.594822212501634e-10, Val R^2: -0.06116674587578661
Epoch 5, Batch 1300/1853, Train Loss: 9.546450201014522e-06, Val Loss: 2.533861878528489e-10, Val R^2: -0.022961331852510446
Epoch 5, Batch 1400/1853, Train Loss: 1.0349852345825639e-05, Val Loss: 2.5124504630772285e-10, Val R^2: -0.01189775512565773
Epoch 5, Batch 1500/1853, Train Loss: 9.913147550832946e-06, Val Loss: 2.5293890371939004e-10, Val R^2: -0.020393730183097016
Epoch 5, Batch 1600/1853, Train Loss: 9.882193808152806e-06, Val Loss: 2.5131250828367953e-10, Val R^2: -0.011093886576156458
Epoch 5, Batch 1700/1853, Train Loss: 9.102921467274427e-06, Val Loss: 2.5160408131197583e-10, Val R^2: -0.012750681722674977
Epoch 5, Batch 1800/1853, Train Loss: 1.0337431376683526e-05, Val Loss: 2.589813061021755e-10, Val R^2: -0.058179864297385336
Epoch 6, Batch 100/1853, Train Loss: 9.535493518342264e-06, Val Loss: 2.55572308755747e-10, Val R^2: -0.035560343684502366
Epoch 6, Batch 200/1853, Train Loss: 9.672560736362357e-06, Val Loss: 2.552178422494555e-10, Val R^2: -0.0335101723502285
Epoch 6, Batch 300/1853, Train Loss: 1.075218642654363e-05, Val Loss: 2.5226647513082747e-10, Val R^2: -0.01653767405135126
Epoch 6, Batch 400/1853, Train Loss: 1.3393612789514009e-05, Val Loss: 2.900256217117868e-10, Val R^2: -0.23800188516246748
Epoch 6, Batch 500/1853, Train Loss: 9.698595022200607e-06, Val Loss: 2.496846779752172e-10, Val R^2: -0.0020723719082821348
Epoch 6, Batch 600/1853, Train Loss: 9.862485967460088e-06, Val Loss: 2.548562988096125e-10, Val R^2: -0.03143193365402907
Epoch 6, Batch 700/1853, Train Loss: 9.599513759894762e-06, Val Loss: 2.5427940248243927e-10, Val R^2: -0.030133364637683967
Epoch 6, Batch 800/1853, Train Loss: 9.83187692327192e-06, Val Loss: 2.608758254911433e-10, Val R^2: -0.06628860676204282
Epoch 6, Batch 900/1853, Train Loss: 9.701487215352245e-06, Val Loss: 2.496843410975719e-10, Val R^2: -0.002170739110430965
Epoch 6, Batch 1000/1853, Train Loss: 9.68287895375397e-06, Val Loss: 2.5408912767483045e-10, Val R^2: -0.02702114979499281
Epoch 6, Batch 1100/1853, Train Loss: 9.90693752100924e-06, Val Loss: 2.503527754585543e-10, Val R^2: -0.005662927934711829
Epoch 6, Batch 1200/1853, Train Loss: 9.274106560042128e-06, Val Loss: 2.5089641902017645e-10, Val R^2: -0.008722453537743945
Epoch 6, Batch 1300/1853, Train Loss: 9.818963008001447e-06, Val Loss: 2.6284780366983885e-10, Val R^2: -0.0811716669298112
Epoch 6, Batch 1400/1853, Train Loss: 9.7711281341617e-06, Val Loss: 2.5150808687350985e-10, Val R^2: -0.012207106152899523
Epoch 6, Batch 1500/1853, Train Loss: 1.0046158422483131e-05, Val Loss: 2.5033071061721556e-10, Val R^2: -0.006311728933866924
Epoch 6, Batch 1600/1853, Train Loss: 9.723602488520555e-06, Val Loss: 2.565765259050232e-10, Val R^2: -0.04136502739057696
Epoch 6, Batch 1700/1853, Train Loss: 9.608912478142884e-06, Val Loss: 2.5237407289810546e-10, Val R^2: -0.01713238157244709
Epoch 6, Batch 1800/1853, Train Loss: 9.80125605565263e-06, Val Loss: 2.5266922887746426e-10, Val R^2: -0.018835835168295692
Epoch 7, Batch 100/1853, Train Loss: 9.360174772155005e-06, Val Loss: 2.497469464503839e-10, Val R^2: -0.002364269016332235
Epoch 7, Batch 200/1853, Train Loss: 9.618866897653788e-06, Val Loss: 2.5849275558725183e-10, Val R^2: -0.05246732228467994
Epoch 7, Batch 300/1853, Train Loss: 1.0350824595661834e-05, Val Loss: 2.5032511209740793e-10, Val R^2: -0.006268182191496811
Epoch 7, Batch 400/1853, Train Loss: 9.504555237072054e-06, Val Loss: 2.509706144583155e-10, Val R^2: -0.009153369477652476
Epoch 7, Batch 500/1853, Train Loss: 9.936795322573744e-06, Val Loss: 2.49676081627288e-10, Val R^2: -0.0020832743526199163
Best model saved to ../model_0327_Mixer/model_best_6_r2_-0.0020832743526199163.pth with Val Loss: 2.49676081627288e-10, Val R^2: -0.0020832743526199163
Epoch 7, Batch 600/1853, Train Loss: 9.329732165497262e-06, Val Loss: 2.507405620125305e-10, Val R^2: -0.007852871023037231
Epoch 7, Batch 700/1853, Train Loss: 9.576762749929912e-06, Val Loss: 2.497991094741092e-10, Val R^2: -0.002965269842475653
Epoch 7, Batch 800/1853, Train Loss: 9.674288776295725e-06, Val Loss: 2.506401497230789e-10, Val R^2: -0.007293374020574533
Epoch 7, Batch 900/1853, Train Loss: 9.715805390442256e-06, Val Loss: 2.4980904294703773e-10, Val R^2: -0.0026878773656749226
Epoch 7, Batch 1000/1853, Train Loss: 9.479106665821746e-06, Val Loss: 2.506726347774449e-10, Val R^2: -0.007454290364491624
Epoch 7, Batch 1100/1853, Train Loss: 9.772531484486535e-06, Val Loss: 2.5036230557490545e-10, Val R^2: -0.005713819333281922
Epoch 7, Batch 1200/1853, Train Loss: 9.779912943486124e-06, Val Loss: 2.499329924208631e-10, Val R^2: -0.0033478382154885217
Epoch 7, Batch 1300/1853, Train Loss: 9.77138006419409e-06, Val Loss: 2.499361441087665e-10, Val R^2: -0.0033737022457808797
Epoch 7, Batch 1400/1853, Train Loss: 1.0497670700715389e-05, Val Loss: 2.525510475857505e-10, Val R^2: -0.01816484727020685
Epoch 7, Batch 1500/1853, Train Loss: 1.0081153050123248e-05, Val Loss: 2.5411649164729377e-10, Val R^2: -0.027150365662086333
Epoch 7, Batch 1600/1853, Train Loss: 1.0110978109878488e-05, Val Loss: 2.5509014356186055e-10, Val R^2: -0.03278186090554334
Epoch 7, Batch 1700/1853, Train Loss: 9.87573184829671e-06, Val Loss: 2.49766776150107e-10, Val R^2: -0.0027548861829518696
Epoch 7, Batch 1800/1853, Train Loss: 9.710388439998496e-06, Val Loss: 2.5040739035754197e-10, Val R^2: -0.0059656323164223694
Epoch 8, Batch 100/1853, Train Loss: 9.311137546319515e-06, Val Loss: 2.4985873289471735e-10, Val R^2: -0.0029456828071041012
Epoch 8, Batch 200/1853, Train Loss: 9.554992175253574e-06, Val Loss: 2.53201868504051e-10, Val R^2: -0.021897921485518373
Epoch 8, Batch 300/1853, Train Loss: 1.011897711578058e-05, Val Loss: 2.5557269132248134e-10, Val R^2: -0.03557096611850403
Epoch 8, Batch 400/1853, Train Loss: 9.843074622040149e-06, Val Loss: 2.4975888079160244e-10, Val R^2: -0.0024290275051963477
Epoch 8, Batch 500/1853, Train Loss: 9.528013833914883e-06, Val Loss: 2.510158331888086e-10, Val R^2: -0.009398296208490855
Epoch 8, Batch 600/1853, Train Loss: 9.770300493983086e-06, Val Loss: 2.496790212139625e-10, Val R^2: -0.00206115777582156
Epoch 8, Batch 700/1853, Train Loss: 9.608712389308494e-06, Val Loss: 2.516866273183903e-10, Val R^2: -0.013212106922963077
Epoch 8, Batch 800/1853, Train Loss: 1.004030946205603e-05, Val Loss: 2.498673332399749e-10, Val R^2: -0.0034121598869877538
Epoch 8, Batch 900/1853, Train Loss: 9.367896382173058e-06, Val Loss: 2.5093323308770827e-10, Val R^2: -0.00893499883637287
Epoch 8, Batch 1000/1853, Train Loss: 9.412767212779727e-06, Val Loss: 2.5215591575421107e-10, Val R^2: -0.01591124505608249
Epoch 8, Batch 1100/1853, Train Loss: 1.0709435628086794e-05, Val Loss: 2.509136660348701e-10, Val R^2: -0.008827549525219486
Epoch 8, Batch 1200/1853, Train Loss: 9.64526134339394e-06, Val Loss: 2.499439647882123e-10, Val R^2: -0.0038953861768999684
Epoch 8, Batch 1300/1853, Train Loss: 9.284663065045606e-06, Val Loss: 2.4999491927389205e-10, Val R^2: -0.0036835667618133716
Epoch 8, Batch 1400/1853, Train Loss: 9.35861226025736e-06, Val Loss: 2.5050152702833566e-10, Val R^2: -0.006506726762146265
Epoch 8, Batch 1500/1853, Train Loss: 9.701486305857543e-06, Val Loss: 2.5062750490345075e-10, Val R^2: -0.007202794211787893
Epoch 8, Batch 1600/1853, Train Loss: 9.835542186920065e-06, Val Loss: 2.543569247811215e-10, Val R^2: -0.028555201766999775
Epoch 8, Batch 1700/1853, Train Loss: 9.670826329966076e-06, Val Loss: 2.510809010826515e-10, Val R^2: -0.009773013263523428
Epoch 8, Batch 1800/1853, Train Loss: 9.148036951955874e-06, Val Loss: 2.55694585515786e-10, Val R^2: -0.03626955816866319
Epoch 9, Batch 100/1853, Train Loss: 9.813766155275516e-06, Val Loss: 2.5005266734979074e-10, Val R^2: -0.003996955785147063
Epoch 9, Batch 200/1853, Train Loss: 9.959081580745988e-06, Val Loss: 2.5070135855134007e-10, Val R^2: -0.007622502136730839
Epoch 9, Batch 300/1853, Train Loss: 9.911931556416675e-06, Val Loss: 2.4982483900627073e-10, Val R^2: -0.0031298937225073395
Epoch 9, Batch 400/1853, Train Loss: 9.67233154369751e-06, Val Loss: 2.5065848552408066e-10, Val R^2: -0.0073846867245926226
Epoch 9, Batch 500/1853, Train Loss: 9.968380254576914e-06, Val Loss: 2.50114533346298e-10, Val R^2: -0.004341647401154985
Epoch 9, Batch 600/1853, Train Loss: 1.0025831215898506e-05, Val Loss: 2.5023310447091765e-10, Val R^2: -0.0049961372814445945
Epoch 9, Batch 700/1853, Train Loss: 9.202259207086172e-06, Val Loss: 2.5176957053595684e-10, Val R^2: -0.013696559549429421
Epoch 9, Batch 800/1853, Train Loss: 9.871840120467823e-06, Val Loss: 2.496905186882906e-10, Val R^2: -0.002102417916894206
Epoch 9, Batch 900/1853, Train Loss: 9.96147809928516e-06, Val Loss: 2.5007248909221547e-10, Val R^2: -0.004099880252410834
Epoch 9, Batch 1000/1853, Train Loss: 9.720723937789444e-06, Val Loss: 2.4971331487259846e-10, Val R^2: -0.002390328530163297
Epoch 9, Batch 1100/1853, Train Loss: 1.0057624422188383e-05, Val Loss: 2.497496919611652e-10, Val R^2: -0.002643990242903845
Epoch 9, Batch 1200/1853, Train Loss: 1.0210100299445912e-05, Val Loss: 2.502843592792357e-10, Val R^2: -0.006023528933461272
Epoch 9, Batch 1300/1853, Train Loss: 1.0171498615818564e-05, Val Loss: 2.496763371387551e-10, Val R^2: -0.002064026120282524
Epoch 9, Batch 1400/1853, Train Loss: 9.734108971315436e-06, Val Loss: 2.56714060654018e-10, Val R^2: -0.04217914029922337
Epoch 9, Batch 1500/1853, Train Loss: 9.599482837074902e-06, Val Loss: 2.49920788876394e-10, Val R^2: -0.0032828444130672536
Epoch 9, Batch 1600/1853, Train Loss: 9.380262781633064e-06, Val Loss: 2.506034914205975e-10, Val R^2: -0.007080689186277733
Epoch 9, Batch 1700/1853, Train Loss: 9.188211151922587e-06, Val Loss: 2.5072350733657336e-10, Val R^2: -0.007747700716325501
Epoch 9, Batch 1800/1853, Train Loss: 9.79029391601216e-06, Val Loss: 2.5005117042505453e-10, Val R^2: -0.004567148055543365
Epoch 10, Batch 100/1853, Train Loss: 9.233574928657617e-06, Val Loss: 2.517723063149248e-10, Val R^2: -0.013704395417381332
Epoch 10, Batch 200/1853, Train Loss: 9.855822099780198e-06, Val Loss: 2.499540767026238e-10, Val R^2: -0.003464821160058797
Epoch 10, Batch 300/1853, Train Loss: 9.52606296777958e-06, Val Loss: 2.4988756840701416e-10, Val R^2: -0.0035526774913902867
Epoch 10, Batch 400/1853, Train Loss: 9.504051377007272e-06, Val Loss: 2.524292660834818e-10, Val R^2: -0.017467556898470904
Epoch 10, Batch 500/1853, Train Loss: 9.62764988798881e-06, Val Loss: 2.498739479964497e-10, Val R^2: -0.003454397149833066
Epoch 10, Batch 600/1853, Train Loss: 9.562569175614044e-06, Val Loss: 2.5060672189696264e-10, Val R^2: -0.007079073061184163
Epoch 10, Batch 700/1853, Train Loss: 9.603348189557437e-06, Val Loss: 2.513413352035884e-10, Val R^2: -0.011240344220950046
Epoch 10, Batch 800/1853, Train Loss: 9.249457434634678e-06, Val Loss: 2.5080163438993506e-10, Val R^2: -0.008180929451684981
Epoch 10, Batch 900/1853, Train Loss: 9.518068509350996e-06, Val Loss: 2.4985505510984245e-10, Val R^2: -0.0029241709622687267
Epoch 10, Batch 1000/1853, Train Loss: 1.0465813829796389e-05, Val Loss: 2.497938127152309e-10, Val R^2: -0.002609168295113347
Epoch 10, Batch 1100/1853, Train Loss: 9.246182344213594e-06, Val Loss: 2.498347984618333e-10, Val R^2: -0.002822935951783781
Epoch 10, Batch 1200/1853, Train Loss: 9.458518434257712e-06, Val Loss: 2.519401355263336e-10, Val R^2: -0.014666168689775376
Epoch 10, Batch 1300/1853, Train Loss: 9.764975402504206e-06, Val Loss: 2.5093650723581916e-10, Val R^2: -0.008949613127875686
Epoch 10, Batch 1400/1853, Train Loss: 9.57706924964441e-06, Val Loss: 2.502036512780012e-10, Val R^2: -0.004836574279362256
Epoch 10, Batch 1500/1853, Train Loss: 9.572507224220317e-06, Val Loss: 2.5207309283007594e-10, Val R^2: -0.015427531044854474
Epoch 10, Batch 1600/1853, Train Loss: 9.385603334521875e-06, Val Loss: 2.4968359129964785e-10, Val R^2: -0.0021585961448443154
Epoch 10, Batch 1700/1853, Train Loss: 9.92768764263019e-06, Val Loss: 2.5012174787013147e-10, Val R^2: -0.004380990897103013
Epoch 10, Batch 1800/1853, Train Loss: 9.700916962174233e-06, Val Loss: 2.4976094748505585e-10, Val R^2: -0.002436656721981085
Test Loss: 2.5061274969994434e-10, R2:-0.007074158288620868
Test Pearson Correlation: -0.02707057171203178